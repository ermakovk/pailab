{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLRepo - A Quick Introduction\n",
    "In this notebook we give a quick introduction working with the repository and explain the basic priniples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     17
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import all things you need to get startes\n",
    "import time\n",
    "import pandas as pd\n",
    "import logging as logging\n",
    "import pprint\n",
    "\n",
    "# Here start the repository specific imports\n",
    "#import pailab.repo as repo\n",
    "import pailab.memory_handler as memory_handler\n",
    "from pailab import RepoInfoKey, MeasureConfiguration, MLRepo, DataSet, MLObjectType, FIRST_VERSION, LAST_VERSION\n",
    "from pailab.job_runner.job_runner import SimpleJobRunner, JobState, SQLiteJobRunner\n",
    "\n",
    "#You may set the loglevel and log-format here. \n",
    "logging.basicConfig(level=logging.FATAL)\n",
    "\n",
    "use_SQLiteJobRunner = False #set True to use external SQLiteJobRunner\n",
    "\n",
    "def wait_for_waiting_jobs(job_runner):\n",
    "    ''' Waits until no job is waiting anymore. It is just use for demonstration purposes so that\n",
    "        the notebook does not lead to errors if run all cells is executed when a asynchronous job runner is used\n",
    "    '''\n",
    "    while len(job_runner.get_waiting_jobs()) > 0:\n",
    "        time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the data\n",
    "As an example machine learning task to ilustrate the way of working with the repository we use the Boston housing data from the  [UCI Machine Learning Repository](http://archive.ics.uci.edu/ml/index.php) where we have applied some preprocessing. The data consists of house prices together with the house features `'RM'`, `'LSTAT'`, and `'PTRATIO'`:\n",
    "- `'RM'` is the average number of rooms among homes in the neighborhood.\n",
    "- `'LSTAT'` is the percentage of homeowners in the neighborhood considered \"lower class\" (working poor).\n",
    "- `'PTRATIO'` is the ratio of students to teachers in primary and secondary schools in the neighborhood.\n",
    "We just read the csv-file containing the data (also in the repository) into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('housing.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a new repository\n",
    "We first create a new repository for our task. The repository is the central key around all functionality is built. Similar to a repository used for source control in classical software development it contains all data and algorithms needed for the machine learning task. The repository needs storages for \n",
    "- scripts containing the machine learning algorithms and interfaces,\n",
    "- numerical objects such as arrays and matrices representing data, e.g. input data, data from the valuation of the models,\n",
    "- json documents representing parameters, e.g. training parameter, model parameter.\n",
    "\n",
    "To keep things simple, we just start using in memory storages. Note that the used memory interfaces are except for testing and playing around not be the first choice, since when ending the session, everything will be lost...\n",
    "\n",
    "In addition to the storages the repository needs a reference to a JobRunner which the platform can use to execute machine learning jobs. For this example we use the most simple one, executing everything sequential in the same thread, the repository runs in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setting up the repository\n",
    "if not use_SQLiteJobRunner:\n",
    "    # for the scripts as well as for parameters we use the same simple in memory handler\n",
    "    handler = memory_handler.RepoObjectMemoryStorage() \n",
    "    # for the numerical objects (numpy) we use the simple NumpyMemoryStorage \n",
    "    numpy_handler = memory_handler.NumpyMemoryStorage()\n",
    "    # and for the sake of being simple, we use a SimpleJobRunner\n",
    "    job_runner = SimpleJobRunner(None)\n",
    "else:\n",
    "    from pailab.disk_handler import RepoObjectDiskStorage\n",
    "    from pailab.numpy_handler_hdf import NumpyHDFStorage\n",
    "    handler = RepoObjectDiskStorage('c:/temp/boston_housing_repo')\n",
    "    numpy_handler = NumpyHDFStorage('c:/temp/boston_housing_repo') \n",
    "    job_runner = SQLiteJobRunner('c:/temp/job_runner.sqlite', None)\n",
    "ml_repo = MLRepo('test_user', handler, numpy_handler, handler, job_runner)\n",
    "job_runner.set_repo(ml_repo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding data\n",
    "The data in the repository is handled by two different data objects:\n",
    "- RawData is the object containing real data.\n",
    "- DataSet is the object conaining the logical data, i.e. a reference to a RawData object together with a specification, which data from the RawData will be used. Here, one can specify a fixed version of the underlying RawData object (then changes to the RawData will not affect the derived DataSet) or a fixed or floating subset of the RawData by defininga start and endindex cutting the derived data just out of the original data.\n",
    "\n",
    "Normally one will add RawData and then define DataSets which are used to train or test a model which is exactly the way shown in the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add RawData. A convenient way to add RawData is simply to use the method add_data.\n",
    "# This method just takes a pandas dataframe and the specification, which columns belong to the input \n",
    "#and which to the targets.\n",
    "ml_repo.add_data('boston_housing', data, input_variables=['RM', 'LSTAT', 'PTRATIO'], target_variables = ['MEDV'])\n",
    "# create DataSet objects for training and test data\n",
    "training_data = DataSet('boston_housing', 0, 300, \n",
    "                            repo_info = {RepoInfoKey.NAME: 'training_data', RepoInfoKey.CATEGORY: MLObjectType.TRAINING_DATA})\n",
    "test_data = DataSet('boston_housing', 301, None, \n",
    "                            repo_info = {RepoInfoKey.NAME: 'test_data',  RepoInfoKey.CATEGORY: MLObjectType.TEST_DATA})\n",
    "# add the objects to the repository. The method returns a dictionary of object names to version numbers of the added objects.\n",
    "version_list = ml_repo.add([training_data, test_data], message = 'add training and test data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When creating the DataSet we have to set two important informations for the repository, given as a dictionary:\n",
    "- The object name. Each object in the repository needs to have a unique name in the repository.\n",
    "- The object type which gives. In our example here we say that we specify that the DataSet are training and test data. Note that on can have only one training data object pre repository while the repository can obtain many different test data sets.\n",
    "\n",
    "Some may wonder what is now stored in *version_list*.\n",
    "** Adding an object (independent if it is a data object or some other object such as a parameter), the object gets a version number and no object will be removed, adding just adds a new version.** The add method returns a dictionary of the object names together with their version number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(version_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a model\n",
    "The next step to do machine learning would be to define a model which will be used in the repository. A model consists of the following pieces\n",
    "- a skript where the code for the model valuation is defined together with the function name of the evaluation method\n",
    "- a skript where the code for the model training is defined together with th function nam of the training method\n",
    "- a model parameter object defining the model parameter and which must have implemented the correct interface so that it can be used within the repository (see the documentation on integrating new objects, normally there is not more to do then just simply add *@repo_object_init()* to the line above your *__init__* method)\n",
    "- a training parameter object defining training parameters (such as number of optimization steps etc.), if necessary for your algorithms (this oen is optional)\n",
    "\n",
    "** SKLearn models as an example**\n",
    "\n",
    "We do not have to define the pieces defined above, if we use the sklearn module. Instead we can use the externals.sklearn module interfacing \n",
    "the sklearn package so that this can be used within the repository. This interface provides a simple method (add_model) to add an arbitrary sklearn model as a model which can be handled by the repository. This method adds a bunch of repo objects to the repository (according to the pieces described above):\n",
    "- An object defining the function to be called to evaluate the model\n",
    "- An object defining the function to be called to train the model\n",
    "- An object defining the model\n",
    "- An object defining the model parameter\n",
    "For the following we just use a DecisionTree as our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import externals.sklearn_interface as sklearn_interface\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "sklearn_interface.add_model(ml_repo, DecisionTreeRegressor(), model_param={'max_depth': 5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "Now, model taining is very simple, since you have defined training and testing data as well as  methods to value and fit your model and the model parameter.\n",
    "So, you can just call *run_training* on the repository, and the training is perfomred automatically.\n",
    "The training job is executed via the JobRunner you specified setting up the repository. All method of the repository involving jobs return the job id when adding the job to the JobRunner so that you can control the status of the task and see if it sucessfully finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "job_id = ml_repo.run_training()  \n",
    "job_info = job_runner.get_info(job_id[0], job_id[1])\n",
    "wait_for_waiting_jobs(job_runner) #wait until all jobs have been finished"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run evaluation\n",
    "To measure errors and to provide plots the model must be evaluated on all test and training datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id = ml_repo.run_evaluation()\n",
    "wait_for_waiting_jobs(job_runner)\n",
    "# print information about the job\n",
    "info = job_runner.get_info(job_id[0][0], job_id[0][1]) \n",
    "print(str(info))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add and compute measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ml_repo.add_measure(MeasureConfiguration.MAX)\n",
    "ml_repo.add_measure(MeasureConfiguration.R2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "job_ids = ml_repo.run_measures()\n",
    "wait_for_waiting_jobs(job_runner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_measure = ml_repo.get('DecisionTreeRegressor/measure/training_data/max')\n",
    "print(str(max_measure.value))\n",
    "max_measure = ml_repo.get('DecisionTreeRegressor/measure/test_data/max')\n",
    "print(str(max_measure.value))\n",
    "print(pprint.pprint(max_measure.repo_info.get_dictionary()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the steps\n",
    "- *run_evaluation*\n",
    "- *run_measures*\n",
    "\n",
    "are not necessary if *run_training* is called with the keyword argument *run_descendants=True*. \n",
    "In This case the repository would have automatically triggered all evaluations and measurement calculations automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Working with the repository\n",
    "This section shows how one can work with the audit and revision functionality of the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in MLObjectType:\n",
    "    names = ml_repo.get_names(k.value)\n",
    "    for n in names: \n",
    "        print(n + '\\t  ' + k.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repository information such as version number, author, date of change are attached to the repo objects and can simply be retrieved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = ml_repo.get('DecisionTreeRegressor/measure/training_data/r2')\n",
    "pprint.pprint(m.repo_info.get_dictionary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The commits can also be queried and printed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in ml_repo.get_commits():\n",
    "    pprint.pprint(k.to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labeling models\n",
    "There is the possibility to label a certain version of a model. The label can then be used to access the model instead of the version number. It is vry useful to\n",
    "compare e.g. the current productive model (labeld e.g. 'prod') against other model versions. abels are supported by many functions and tools and make life much easier. So the consistency checks only check for the latest and labeled models if there are changes make a rerun of training/evaluation/measures needed. Also som figures will automatically highlight the results belonging to labeled versions.\n",
    "\n",
    "Let us label the latest model version in the repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ml_repo.set_label('prod', 'DecisionTreeRegressor/model', message='we found our first production model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change model parameter, check consistency and train\n",
    "Pailab's *tools*-submodule provides functionality to check for consistency and quality issues as well as for outstanding tasks (such as rerunning a training after the training set has been changed). We ilustrate the functionality for the case that we modify a model parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = ml_repo.get('DecisionTreeRegressor/model_param')\n",
    "param.sklearn_params['max_depth'] = 2\n",
    "version = ml_repo.add(param)\n",
    "print(param.sklearn_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we have changed the model parameter, we use the *tools* submodules *check_model* method for open tasks/inconsistencies. We see that the output shows that the models last version has been calibrated using a different model parameter version then the current version. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pailab.tools as tools\n",
    "results = tools.check_model(ml_repo, 'DecisionTreeRegressor')\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can resolve this issue by simply training the model again (now on the new training data set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ml_repo.run_training()\n",
    "wait_for_waiting_jobs(job_runner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = tools.check_model(ml_repo, 'DecisionTreeRegressor')\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ml_repo.run_evaluation()\n",
    "wait_for_waiting_jobs(job_runner)\n",
    "ml_repo.run_measures()\n",
    "wait_for_waiting_jobs(job_runner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure = ml_repo.get('DecisionTreeRegressor/measure/test_data/r2',version = (0,100))\n",
    "for x in measure:\n",
    "    print(str(x.repo_info))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Easy access to repo objects and names\n",
    "Since the names are chosen equally to a directory structure (with subdirectories) they may be long and difficult to remember (especialls the order). And even if one remembers the long names, it is a lot of work to type them. Here, the tools module provides a  very elegant solution for this problem, as long as you are using it in a python framework where autocompletion works (such as jupyter). You can simply create such an object by calling the method path_to_names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_paths = tools.path_to_names(ml_repo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you now type th objects name followd by a '.' by pressing tab you will see the possible next solutions makin it very easy to 'browse' to the object's name you have in mind. By using '()' operator you get a list of names below th current naming level, and in addition you can filter the names by giving a string: Only names containing this string are put into the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(repo_paths.DecisionTreeRegressor.measure())\n",
    "print(repo_paths.DecisionTreeRegressor.measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_paths.DecisionTreeRegressor.measure.test_data.max.load()\n",
    "repo_paths.DecisionTreeRegressor.measure.test_data.max.obj.value = 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_paths.DecisionTreeRegressor.modifications(commit = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_paths.DecisionTreeRegressor.modifications()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append RawData\n",
    "One can append data to the RawData object. The repository manages which objects are affected by appending data and directly updates these objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = ml_repo.get_training_data(full_object = False)\n",
    "print(train_data.repo_info[RepoInfoKey.NAME] +': ' +str(train_data))\n",
    "test_data = ml_repo.get_names(MLObjectType.TEST_DATA)\n",
    "for k in test_data:\n",
    "    t = ml_repo.get(k)\n",
    "    print(str(t)+ ' Version: ' + str(t.repo_info[RepoInfoKey.VERSION]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "ml_repo.append_raw_data('boston_housing', x_data = array([[ 6.575, 4.98, 15.3]]), y_data =array([[504000.0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.repo_info[RepoInfoKey.NAME] +': ' +str(train_data))\n",
    "for k in test_data:\n",
    "    t = ml_repo.get(k)\n",
    "    print(str(t) + ' Version: ' + str(t.repo_info[RepoInfoKey.VERSION]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = tools.check_model(ml_repo, 'DecisionTreeRegressor')\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Repo-Analysis\n",
    "Having parameters, evaluations, measures in one place enables out of the box analysis- and plotting functionality. The submodule *plot* provides automated, standardized plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pailab.plot as plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for j in range(2):\n",
    "    training_data = ml_repo.get('training_data')\n",
    "    training_data.end_index += 50\n",
    "    ml_repo.add(training_data, message='add 50 datapoints to end_index')\n",
    "    for i in range(6,12):\n",
    "        #print(i)\n",
    "        param = ml_repo.get('DecisionTreeRegressor/model_param')\n",
    "        param.sklearn_params['max_depth'] = i\n",
    "        version = ml_repo.add(param)\n",
    "        ml_repo.add(param)\n",
    "        ml_repo.run_training()\n",
    "        ml_repo.run_evaluation()\n",
    "        ml_repo.run_measures()\n",
    "        if j == 1 and i==6:\n",
    "            ml_repo.set_label('prod', 'DecisionTreeRegressor/model', message='')\n",
    "        if j == 1 and i==8:\n",
    "            ml_repo.set_label('candidate', 'DecisionTreeRegressor/model', message='')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting\n",
    "### Plot errors and measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot error measure vs parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pailab.plot_helper as plt_helper\n",
    "import pailab.plot as plot\n",
    "#if False:\n",
    "#print(pd.DataFrame(\n",
    "#plt_helper.get_measure_by_model_parameter(ml_repo, 'DecisionTreeRegressor/measure/test_data/r2', 'max_depth')\n",
    "#))\n",
    "plot.measure_by_model_parameter(ml_repo, ['DecisionTreeRegressor/measure/training_data/r2', 'DecisionTreeRegressor/measure/test_data/r2'], 'max_depth', data_versions=FIRST_VERSION)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot error vs input variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.scatter_model_error(ml_repo, 'DecisionTreeRegressor/model', 'test_data', 'PTRATIO')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot histogram of model error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.histogram_model_error(ml_repo, 'DecisionTreeRegressor/model', 'test_data', )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.histogram_data(ml_repo, {'test_data':['last'], 'training_data': ['first','last']}, x_coordinate = 'PTRATIO') #, y_coordinate='MEDV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "786px",
    "left": "0px",
    "right": "1470.45px",
    "top": "65.9943px",
    "width": "260px"
   },
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
